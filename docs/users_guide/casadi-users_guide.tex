\documentclass[a4paper,12pt]{book}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{a4wide}
%\usepackage[bookmarks=false,breaklinks=true,pdfstartview=Fit]{hyperref}
\usepackage{amsfonts}
\usepackage{amsmath}
%\usepackage{listings}
% \usepackage{color}
\usepackage[usenames,dvipsnames]{color}
\usepackage{html}
%\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{pytex}
\usepackage{xspace}

% \#c4ebff;

\newcommand{\n}{\\n}
\newcommand{\CasADi}{\texttt{CasADi}\xspace}
\newcommand{\trace}[1]{\text{tr}(#1)}



\begin{latexonly}
%\ifunction\currentversion\undefined \newcommand{\currentversion}{1.9.0\xspace} \fi
\end{latexonly}
\begin{htmlonly}
\newcommand{\currentversion}{currentversionplaceholder}
\end{htmlonly}

\begin{htmlonly}
\newcounter{pytexcount}
\newcounter{pytexsubcount}
\newcounter{pytexlinecountstart}
\newcounter{pytexlinecountend}

\setcounter{pytexcount}{0}
\setcounter{pytexlinecountstart}{0}
\setcounter{pytexlinecountend}{0}

% Assign a new header
\newenvironment{pytexTemplate}[1]{
\begin{rawhtml}
<div style="display:none">
\end{rawhtml}
}{
\begin{rawhtml}
</div>
\end{rawhtml}
}

\newcommand{\pytexStart}[1]{
  \addtocounter{pytexcount}{1}%   'pytexcount'++
  \setcounter{pytexsubcount}{0}%  reset 'pytexsubcount'
}

\renewenvironment{pytex}
{\addtocounter{pytexsubcount}{1}%                                             'pytexsubcount'++
  %                                                                            each line is added to accumulator
\begin{rawhtml}
<div style="color: black; background-color: \#b9c8db;  border-style: dotted; border-width: 1px; padding:2px;padding-left:1em" >
<pre>
\end{rawhtml}
}%
{\begin{rawhtml}
</pre>
</div>
<div style="color: black; background-color: \#fffff;  border-style: solid; border-width: 1px; padding:2px;padding-left:1em;margin-left:1em;" >\end{rawhtml}%
\verbatiminputeval{pytex_\alph{pytexcount}_\arabic{pytexsubcount}.log}%
\begin{rawhtml}
</div>
\end{rawhtml}
}
\renewenvironment{pytexoutput}
{\addtocounter{pytexsubcount}{1}%                                             'pytexsubcount'++
  %                                                                            each line is added to accumulator
\begin{rawhtml}
<div style="display:none">
<pre>
\end{rawhtml}
}%
{\begin{rawhtml}
</pre>
</div>
<div style="color: black; background-color: \#fffff;  border-style: solid; border-width: 1px; padding:2px;padding-left:1em;margin-left:1em;" >\end{rawhtml}%
\verbatiminputeval{pytex_\alph{pytexcount}_\arabic{pytexsubcount}.log}%
\begin{rawhtml}
</div>
\end{rawhtml}
}
\newcommand{\codebegin}{
\begin{rawhtml}
<div style="color: black; background-color: \#b9c8db;  border-style: dotted; border-width: 1px;padding:2px;padding-left:1em" >
\end{rawhtml}
}
\newcommand{\codeend}{
\begin{rawhtml}
</div>
\end{rawhtml}
}
\end{htmlonly}

%\begin{latexonly}
\newcommand{\codebegin}{

}
\newcommand{\codeend}{

}
%\end{latexonly}

\author{Joel Andersson \and Joris Gillis \and Moritz Diehl}
\title{User Documentation for \CasADi v\currentversion}
\begin{document}
%\htmlinfo*
%\sffamily
\titlepage
\maketitle
%\clearpage
\begin{latexonly}
\tableofcontents
\end{latexonly}
\clearpage

\chapter{Introduction}
This document aims to give an introduction to \CasADi, an open-source software tool for numerical optimization in
general and optimal control (i.e. optimization involving differential equations) in particular.
\CasADi was developed by Joel Andersson and Joris Gillis while PhD students at the Optimization in Engineering Center
(OPTEC) of the KU Leuven under supervision of Moritz Diehl.

After reading this document, you should be able to formulate and manipulate expressions in \CasADi's symbolic framework, generate derivative information efficiently using \emph{algorithmic differentiation}, to set up, solve and perform forward and adjoint sensitivity analysis for systems of ordinary differential equations (ODE) or differential-algebraic equations (DAE) as well as to formulate and solve nonlinear programs (NLP) problems and optimal control problems (OCP). CasADi is available for C++, Python and MATLAB with little or no difference in performance. We recommend new users to try out Python first, as it is
more stable than the MATLAB interface and, unlike C++, allows interactivity. It is also by far the best documented.

\section{What \CasADi is and what it is \emph{not}}
\CasADi started out as a tool for algorithmic differentiation (AD) using a syntax borrowed from computer algebra systems (CAS), which explains its name. While AD still forms one of the core functionalities of the tool, the scope of the tool has since been considerably broadened, with the addition of support for ODE/DAE integration and sensitivity analysis, nonlinear programming and interfaces to other numerical tools. In its current form, it is a general-purpose tool for gradient-based numerical optimization -- with a strong focus on optimal control -- and ``\CasADi'' is just a name without any particular meaning.

It is important to point out that \CasADi is \emph{not} a conventional AD tool, that can be used to calculate derivative information from existing user code with little to no modification. If you have an existing model written in C++, Python or MATLAB, you need to be prepared to reimplement the model using \CasADi syntax.

Secondly, \CasADi is \emph{not} a computer algebra system. While the symbolic core does include an increasing set of tools for manipulate symbolic expressions, these capabilities are very limited compared to a proper CAS tool.

Finally, \CasADi is not an ``optimal control problem solver'', that allows the user to enter an OCP and then gives the solution back. Instead, it tries to provide the user with a set of ``building blocks'' that can be used to implement general-purpose or specific-purpose OCP solvers efficiently with a modest programming effort.

\section{Help and support} \label{sec:support}
If you find simple bugs or lack some feature that you think would be relatively easy for us to add, the simplest thing is simply to write to the forum, located at \htmladdnormallink{http://forum.casadi.org}{http://forum.casadi.org/}. We check the forum regularly and try to respond as soon as possible. The only thing we expect for this kind of support is that you cite us, cf. Section~\ref{sec:citing}, whenever you use \CasADi in scientific work.

If you want more help, we are always open for academic or industrial cooperation. An academic cooperation usually take the form of a co-authorship of a peer reviewed paper, and an industrial cooperation involves a negotiated consulting contract. Please contact the us directly if you are interested in this.

\section{Citing \CasADi} \label{sec:citing}
If you use \CasADi in published scientific work, please cite the following:
\begin{verbatim}
@PHDTHESIS{Andersson2013b,
  author = {Joel Andersson},
  title = {{A} {G}eneral-{P}urpose {S}oftware {F}ramework for
           {D}ynamic {O}ptimization},
  school = {Arenberg Doctoral School, KU Leuven},
  year = {2013},
  type = {{P}h{D} thesis},
  address = {Department of Electrical Engineering (ESAT/SCD) and
             Optimization in Engineering Center,
             Kasteelpark Arenberg 10, 3001-Heverlee, Belgium},
  month = {October}
}
\end{verbatim}

\section{Reading this document}
The goal of this document is to make the reader familiar with the syntax of \CasADi and provide easily available building blocks to build numerical optimization and dynamic optimization software. Our explanation is mostly program code driven and provides little mathematical background knowledge. We assume that the reader already has a fair knowledge of theory of optimization theory, solution of initial-value problems in differential equations and the programming language in question (C++, Python or MATLAB).

We will use Python and MATLAB syntax side-by-side in this guide, noting that the Python interface is significantly more stable and better documented. We try to point out the instances where has a diverging syntax. To facilitate switching between the programming languages, we also list the major differences in Chapter~\ref{ch:syntax_differences}.

\chapter{Obtaining and installing \CasADi}
\CasADi is an open-source tool, available under LGPL license, which is a permissive license that allows the tool to be used royalty-free also in commercial closed-source applications. The source code is hosted on Github and has a core written in self-contained C++ code, relying on nothing but the C++ Standard Library. Its front-ends to Python and MATLAB are full-featured and auto-generated using the tool \htmladdnormallink{SWIG}{http://www.swig.org/}. The interfaces are unlikely to result in noticeable loss of efficiency. \CasADi has been compiled and used successfully on Linux, OS X and Windows.

For up-to-date installation instructions, we refer to the \CasADi's website, \htmladdnormallink{casadi.org}{http://casadi.org/}.

\chapter{Symbolic framework}
At the core of \CasADi, is a self-contained symbolic framework that allows the user to construct symbolic expressions using a MATLAB inspired everything-is-a-matrix data type, i.e. vectors are treated as n-by-1 matrices and scalars as 1-by-1 matrices. All matrices are \emph{sparse} and use a general sparse format -- \emph{compressed column storage} (CCS) -- to store matrices\footnote{Before v1.9.0, \emph{compressed row storage} (CRS) was used.}. In the following, we introduce the most fundamental classes of this framework.

\section{The \texttt{SX} symbolics}
The \texttt{SX} data type is used to represent matrices whose elements consist of symbolic expressions made up by a sequence of unary and binary operations. To see how it works in practice, start an interactive Python shell (e.g. by typing \texttt{ipython} from a Linux terminal or inside a integrated development environment such as Spyder) or launch MATLAB. Assuming \CasADi has been installed correctly, you can import the symbols into the workspace as follows:

\pytexStart{empty}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
from casadi import *
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
import casadi.*
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
from casadi import *
\end{pytexoutput}

For reference, In C++ the equivalent would be to import \CasADi's public header
file (''\lstinline[language=C++]{#import <casadi/casadi.hpp>}'') and getting the
symbols in the \texttt{casadi} namespace
(''\lstinline[language=C++]{using namespace casadi;}'').

Now create the variable \texttt{x} using the syntax\footnote{Since declaring
types is necessary in C++ and since colon (":") is used to call static functions,
the C++ equivalent is \lstinline[language=C++]{SX x = SX::sym("x");}}:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
x = MX.sym('x')
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
x = MX.sym('x');
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
x = MX.sym('x')
\end{pytexoutput}

This creates a 1-by-1 matrix, i.e. a scalar containing a symbolic primitive called ``x''. This is just the display name, not the identifier. Multiple variables can have the same name, but still be different. You can also create vector- or matrix-valued symbolic variables by supplying additional arguments to
\lstinline[language=Python]{SX.sym}:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
y = SX.sym('y',5)
Z = SX.sym('Z',4,2)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
y = SX.sym('y',5);
Z = SX.sym('Z',4,2);
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
y = SX.sym('y',5)
Z = SX.sym('Z',4,2)
\end{pytexoutput}

which creates a 5-by-1 matrix, i.e. a vector, and a 4-by-2 matrix with symbolic primitives, respectively.

\lstinline[language=Python]{SX.sym} is a (static) function which returns an \texttt{SX} instance. When variables have been declared, expressions can now be formed in an intuitive way:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
f = x**2 + 10
f = sqrt(f)
print f
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
f = x^2 + 10;
f = sqrt(f);
disp f
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
f = x**2 + 10
f = sqrt(f)
print f
\end{pytexoutput}

You can also create constant \texttt{SX} instances \emph{without} any symbolic primitives:
\begin{itemize}
  \item[] \lstinline[language=Python]{B1 = SX.zeros(4,5)}: A dense 4-by-5 empty matrix with all zeros
  Create an $n$-by-$m$ symbolic primitive
  \item[] \lstinline[language=Python]{B2 = SX(4,5)}: A sparse 4-by-5 empty matrix with all zeros
  \item[] \lstinline[language=Python]{B4 = SX.eye(4)}: A sparse 4-by-4 matrix with ones on the diagonal
\end{itemize}

\begin{pytexoutput}
B1 = SX.zeros(4,5)
B2 = SX(4,5)
B4 = SX.eye(4)
\end{pytexoutput}


Note the difference between a sparse matrix with \emph{structural} zeros and a dense matrix with \emph{actual} zeros. When printing an expression with structural zeros, these will be represented as $00$ to distinguish them from actual zeros $0$:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
print B4
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
disp B4
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
print B4
\end{pytexoutput}

The following list summarizes the most commonly used ways of constructing new \texttt{SX} expressions:
\begin{itemize}
  \item \lstinline[language=Python]{SX.sym(name,n,m)}: Create an $n$-by-$m$ symbolic primitive
  \item \lstinline[language=Python]{SX.zeros(n,m)}: Create an $n$-by-$m$ dense matrix with all zeros
  \item \lstinline[language=Python]{SX(n,m)}: Create an $n$-by-$m$ sparse matrix with all \emph{structural} zeros
  \item \lstinline[language=Python]{SX.ones(n,m)}: Create an $n$-by-$m$ dense matrix with all ones
  \item \lstinline[language=Python]{SX.repmat(v,n,m)}: Repeat expression $v$ $n$ times vertically and $m$ times horizontally. \lstinline[language=Python]{repmat(SX(3),2,1)} will create a 2-by-1 matrix with all elements 3.
  \item \lstinline[language=Python]{SX.eye(n)}: Create an $n$-by-$n$ diagonal matrix with ones on the diagonal and structural zeros elsewhere.
  \item \lstinline[language=Python]{SX(scalar_type)}: Create a scalar (1-by-1 matrix) with value given by the argument. This method can be used explicitly, e.g. \lstinline[language=Python]{SX(9)}, or implicitly, e.g. \lstinline[language=Python]{9 * SX.ones(2,2)}.
  \item \lstinline[language=Python]{SX(matrix_type)}: Create a matrix given a numerical matrix given as a \emph{numpy} or \emph{scipy} matrix (in Python) or as a dense or sparse matrix (in MATLAB). In MATLAB e.g.
  \lstinline[language=Matlab]{SX([1,2,3,4])} for a row vector, \lstinline[language=Matlab]{SX([1;2;3;4])} for a column vector and \lstinline[language=Matlab]{SX([1,2;3,4])} for a 2-by-2 matrix. This method can be used explicitly or implicitly.
  \item (\emph{Python only}) \lstinline[language=Python]{SX(list)}: Create a column vector ($n$-by-1 matrix) with the elements in the list, e.g. \lstinline[language=Python]{SX([1,2,3,4])} (note the difference between Python lists and MATLAB horizontal concatination, which both uses square bracket syntax)
  \item (\emph{Python only}) \lstinline[language=Python]{SX(list of list)}: Create a dense matrix with the elements in the lists, e.g. \lstinline[language=Python]{SX([[1,2],[3,4]])} or a row vector (1-by-$n$ matrix) using \lstinline[language=Python]{SX([[1,2,3,4]])}.
\end{itemize}

\section{\texttt{DMatrix}}
\texttt{DMatrix} is very similar to \texttt{SX} (in fact, they are just two template instantiations of the same C++ class \lstinline[language=C++]{casadi::Matrix<T>}), but with the difference that the nonzero elements are numerical values and not symbolic expressions. The syntax is also the same, except for functions such as \texttt{SX.sym}, which have no equivalents.

\texttt{DMatrix} is mainly used for storing matrices in \CasADi and as inputs and outputs of functions. It is \emph{not} intended to be used for computationally intensive calculations. For this purpose, use the builtin dense or sparse data types in MATLAB, \texttt{numpy} or \texttt{scipy} matrices in Python or an expression template based library such as \texttt{eigen}, \texttt{ublas} or \texttt{MTL} in C++. Conversion between the types is usually straightforward:

\begin{minipage}[t]{0.5\textwidth}
\begin{pytex}
# Python
C = DMatrix(2,3)

from numpy import array
C_numpy = array(C)

from scipy.sparse import csc_matrix
C_scipy = csc_matrix(C)
\end{pytex}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
  \begin{lstlisting}[language=Matlab]
  % MATLAB
  C = DMatrix(2,3)

  C_dense = full(C)

  C_sparse = sparse(C)
  \end{lstlisting}
\end{minipage}

More usage examples for \texttt{SX} can be found in the tutorials at \htmladdnormallink{http://docs.casadi.org}{http://docs.casadi.org/}. For documentation of particular functions of this class (and others), find the ``C++ API docs'' on the website and search for information about \lstinline[language=C++]{casadi::Matrix<T>}.

\section{The \texttt{MX} symbolics}
Let us perform a simple operation using the \texttt{SX} above:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
x = SX.sym('x',2,2)
y = SX.sym('y')
f = 3*x + y
print f
print f.shape
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
x = SX.sym('x',2,2);
y = SX.sym('y');
f = 3*x + y;
disp(f)
disp(f.size)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
x = SX.sym('x',2,2)
y = SX.sym('y')
f = 3*x + y
print f
print f.shape
\end{pytexoutput}

As you can see, the output of this operation is a 2-by-2 matrix. Note how the multiplication and the addition were performed elementwise and new expressions (of type \texttt{SX}) were created for each entry of the result matrix.

We shall now introduce a second, more general \emph{matrix expression} type \texttt{MX}. The \texttt{MX} type allows, like \texttt{SX}, to build up expressions consisting of a sequence of elementary operations. But unlike \texttt{SX}, these elementary operations are not restricted to be scalar unary or binary operations ($\mathbb{R} \rightarrow \mathbb{R}$ or $\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$. Instead the elementary operations that are used to form \texttt{MX} expressions are allowed to be general \emph{multiple sparse-matrix valued} input, \emph{multiple sparse-matrix valued} output functions: $\mathbb{R}^{n_1 \times m_1} \times \ldots \times \mathbb{R}^{n_N \times m_N} \rightarrow \mathbb{R}^{p_1 \times q_1} \times \ldots \times \mathbb{R}^{p_M \times q_M}$.

The syntax of \texttt{MX} is intended to mirror that of \texttt{SX}:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
x = MX.sym('x',2,2)
y = MX.sym('y')
f = 3*x + y
print f
print f.shape
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
x = MX.sym('x',2,2);
y = MX.sym('y');
f = 3*x + y;
disp(f)
disp(f.shape)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
x = MX.sym('x',2,2)
y = MX.sym('y')
f = 3*x + y
print f
print f.shape
\end{pytexoutput}

Note that this operation required only 2 elementary operations (one multiplication and one addition) using \texttt{MX} symbolics, whereas the \texttt{SX} symbolics required 8 (2 for each element of the resulting matrix). As a consequence, \texttt{MX} can be more economical when working with operations that are naturally vector or matrix valued with many elements. As we shall see in Chapter~\ref{ch:function}, it is also much more general since we allow calls to arbitrary functions that cannot be expanded in terms of elementary operations.

\texttt{MX} supports getting and setting elements, using the same syntax as \texttt{SX}, but the way it is implemented is very different. Test, for example, to print the element in the upper-left corner of a 2-by-2 symbolic variable:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
x = MX.sym('x',2,2)
print x[0,0]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
x = MX.sym('x',2,2);
disp(x(1,1))
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
x = MX.sym('x',2,2)
print x[0,0]
\end{pytexoutput}

The output should be understood as an expression that is equal to the first (i.e. index 0 in C++) structurally non-zero element of \texttt{x}, unlike \texttt{x\_0} in the \texttt{SX} case above, which is the name of a symbolic primitive in the first (index 0) location of the matrix.

Similar results can be expected when trying to set elements (cf. Section~\ref{sec:getset}):

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
x = MX.sym('x',2)
A = MX(2,2)
A[0,0] = x[0]
A[1,1] = x[0]+x[1]
print A
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
x = MX.sym('x',2);
A = MX(2,2);
A(1,1) = x(1);
A(2,2) = x(1)+x(2);
disp(A)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
x = MX.sym('x',2)
A = MX(2,2)
A[0,0] = x[0]
A[1,1] = x[0]+x[1]
print A
\end{pytexoutput}

The interpretation of the (admittedly cryptic) output is that to a diagonal 2-by-2 matrix with structural zeros off the diagonal and actual zeros on the diagonal (\lstinline{Const<0>(2x2: diagonal)}), the diagonal entries are set to \texttt{x\_0} and \texttt{x\_0+x\_1}, respectively.

Element access and assignment, of the type you have just seen, are examples of operations that can be used to construct expressions. Other examples of operations are matrix multiplications, transposes, concatenations, resizings and reshapings.

\section{Mixing \texttt{SX} and \texttt{MX}}
You can \emph{not} multiply an \texttt{SX} object with an \texttt{MX} object, or perform any other operation to mix the two in the same expression graph. You can, however, in an \texttt{MX} graph include calls to a \emph{function} defined by \texttt{SX} expression. This will be demonstrated in Chapter~\ref{ch:function}. Mixing \texttt{SX} and \texttt{MX} is often a good idea since functions defined by \texttt{SX} expressions have a much lower overhead per operation making it much faster for operations that are naturally written as a sequence of scalar operations. The \texttt{SX} expressions are thus intended to be used for low level operations (for example the DAE right hand side, cf. Chapter~\ref{ch:integrators}), whereas the \texttt{MX} expressions act as a glue and enables the formulation of e.g. the constraint function of an NLP (which might contain calls to ODE/DAE integrators, or might simply be too large to expand as one big expression).

\section{The \texttt{Sparsity} class} \label{sec:sparsity_class}
As mentioned above, matrices in \CasADi are stored using the \emph{compressed column storage} (CCS) format. This is a standard format for sparse matrices that allows linear algebra operations such as elementwise operations, matrix multiplication and transposes to be performed efficiently. In the CCS format, the sparsity pattern is decoded using the dimensions -- the number of rows and number of columns -- and two vectors. The first vector contains the index of the first structurally nonzero element of each column and the second vector contains the row index for every nonzero element. For more details on the CCS format, see e.g. \htmladdnormallink{Templates for the Solution of Linear Systems}{http://netlib.org/linalg/html_templates/node92.html} on Netlib. Note that \CasADi uses the CCS format for sparse as well as dense matrices.

Sparsity patterns in \CasADi are \emph{reference-counted}, meaning that multiple matrices can share the same sparsity pattern, including \texttt{MX} expression graphs and instances of \texttt{SX} and \texttt{DMatrix}. The \texttt{Sparsity} class is also \emph{cached}, meaning that the creation of multiple instances of the same sparsity patterns is always avoided.

The following list summarizes the most commonly used ways of constructing new sparsity patterns:
\begin{itemize}
  \item \lstinline[language=Python]{Sparsity.dense(n,m)}: Create a dense $n$-by-$m$ sparsity pattern
  \item \lstinline[language=Python]{Sparsity(n,m)}: Create a sparse $n$-by-$m$ sparsity pattern
  \item \lstinline[language=Python]{Sparsity.diag(n)}: Create a diagonal $n$-by-$n$ sparsity pattern
  \item \lstinline[language=Python]{Sparsity.upper(n)}: Create an upper triangular $n$-by-$n$ sparsity pattern
  \item \lstinline[language=Python]{Sparsity.lower(n)}: Create a lower triangular $n$-by-$n$ sparsity pattern
\end{itemize}

The \texttt{Sparsity} class can be used to create non-standard matrices, e.g.

\begin{minipage}[t]{0.7\textwidth}
\begin{lstlisting}[language=Python]
# Python
print SX.sym('x',Sparsity.lower(3))
\end{lstlisting}
\begin{lstlisting}[language=Matlab]
% MATLAB
disp(SX.sym('x',Sparsity.lower(3)))
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}

\begin{pytexoutput}
print SX.sym('x',Sparsity.lower(3))
\end{pytexoutput}
\end{minipage}

\subsection{Getting and setting elements in matrices}
To get or set an element or a set of elements in \CasADi's matrix types (\texttt{SX}, \texttt{MX} and \texttt{DMatrix}), we use square brackets in Python and round brackets in C++ and MATLAB. As is conventional in these languages, indexing starts from zero in C++ and Python but from one in MATLAB. In Python and C++, we allow negative indices to specify an index counted from the end. In MATLAB, use the \texttt{end} keyword for indexing from the end.

Indexing can be done with one index or two indices. With two indices, you reference a particular row (or set or rows) and a particular column (or set of columns). With one index, you reference an element (or set of elements) starting from the upper left corner and columnwise to the lower right corner. All elements are counted regardless of whether they are structurally zero or not.

In Python and C++, , while in MATLAB indexing starts from one. In Python, negative indices to specify an index counted from the end of a list.

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
M = SX([[3,7],[4,5]])
print M[0,:]
M[0,:] = 1
print M
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
M = SX([3,7;4,5]);
disp(M(1,:))
M(1,:) = 1;
disp(M)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
M = SX([[3,7],[4,5]])
print M[0,:]
M[0,:] = 1
print M
\end{pytexoutput}

Unlike NumPy, \CasADi slices are not views into the data of the left hand side; rather, a slice access copies the data. As a result, the matrix $M$ is not changed in the following example:

\begin{pytex}
# Python
M = SX([[3,7],[4,5]])
M[0,:][0,0] = 1
print M
\end{pytex}

Getting and setting matrix elements be elaborated in the following. The discussion applies to all of \CasADi's matrix types.

\paragraph{Single element access} is getting or setting by providing a row-column pair or its flattened index (columnwise starting in the upper left corner of the matrix):

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
# Python
M = diag(SX([3,4,5,6]))
print M
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
% MATLAB
M = diag(SX([3,4,5,6]));
disp(M)
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
M = diag(SX([3,4,5,6]))
print M
\end{pytexoutput}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print M[0,0], M[1,0], M[-1,-1]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp M(1,1), M(2,1), M(end,end)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
print M[0,0], M[1,0], M[-1,-1]
\end{pytexoutput}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print M[5], M[-6]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp M(6), M(end-5)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
print M[5], M[-6]
\end{pytexoutput}


\paragraph{Slice access} means setting multiple elements at once. This is significantly more efficient than setting the elements one at a time. You get or set a slice by providing a (\emph{start},\emph{stop},\emph{step}) triple. In Python and MATLAB, \CasADi uses standard syntax:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print M[:,1]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp M(:,2)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
print M[:,1]
\end{pytexoutput}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print M[1:,1:4:2]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp M(2:end,2:2:4)
\end{lstlisting}
\end{minipage}

\begin{pytexoutput}
print M[1:,1:4:2]
\end{pytexoutput}

In C++, \CasADi's \texttt{Slice} helper class can be used. For the example above, this means \lstinline[language=C++]{M(Slice(),1)} and \lstinline[language=C++]{M(Slice(1,-1),Slice(1,4,2))}, respectively.

\paragraph{List access} are similar to (but potentially less efficient than) slice access:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
M = SX([[3,7,8,9],[4,5,6,1]])
print M
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
M = SX([3 7 8 9; 4 5 6 1])
disp(M)
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
M = SX([[3,7,8,9],[4,5,6,1]])
print M
\end{pytexoutput}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print M[0,[0,3]], M[[5,-6]]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp M(1,[1,4]), M([6,numel(M)-5])
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
print M[0,[0,3]], M[[5,-6]]
\end{pytexoutput}

\section{Arithmetic operations}
\CasADi supports basic such as addition, multiplications, powers, trigonometric functions etc:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x')
y = SX.sym('y',2,2)
print sin(y)-x
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x');
y = SX.sym('y',2,2);
disp sin(y)-x
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x')
y = SX.sym('y',2,2)
print sin(y)-x
\end{pytexoutput}

In C++ and Python (but not in MATLAB), the standard multiplication operation (using \verb|*|) is reserved for elementwise multiplication (in MATLAB \verb|.*|). For \textbf{matrix multiplication}, use
\lstinline[language=Python]{mul(A,B)}:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print y*y, mul(y,y)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp y.*y, y*y
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
print y*y, mul(y,y)
\end{pytexoutput}

As is customary in MATLAB, multiplication using \verb|*| and \verb|.*| are equivalent when either of the arguments is a scalar.

\textbf{Transposes} are formed using the syntax \lstinline[language=Python]{A.T}, \lstinline[language=Python]{A.T()} or \lstinline[language=Python]{transpose(A)} in C++ and with
\lstinline[language=Python]{A'} or \lstinline[language=Python]{A.'} in MATLAB:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print y.T
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp y'
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
print y.T
\end{pytexoutput}

\textbf{Reshaping} means changing the number of rows and columns but retaining the number of elements and the relative location of the nonzeros. This is a computationally very cheap operation which is performed using the syntax:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.eye(4)
print reshape(x,(2,8))
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.eye(4);
disp reshape(x,(2,8))
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.eye(4)
print reshape(x,(2,8))
\end{pytexoutput}

\textbf{Concatenation} means stacking matrices horizontally or vertically. Due to the column-major way of storing elements in \CasADi, it is most efficient to stack matrices horizontally. Matrices that are in fact column vectors (i.e. consisting of a single column), can also be stacked efficiently vertically. Vertical and horizontal concatenation is performed using the functions \texttt{vertcat} and \texttt{horzcat} (that take a list of input arguments) in Python and C++ and with square brackets in MATLAB:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x',5)
y = SX.sym('y',5)
print vertcat([x,y])
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x',5);
y = SX.sym('y',5);
disp [x;y]
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x',5)
y = SX.sym('y',5)
print vertcat([x,y])
\end{pytexoutput}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print horzcat([x,y])
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp [x,y]
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
print horzcat([x,y])
\end{pytexoutput}

\textbf{Horizontal and vertical splitting} are the inverse operations of the above introduced horizontal and vertical concatenation. To split up an expression horizontally into $n$ smaller expressions, you need to provide, in addition to the expression being splitted, a vector \emph{offset} of length $n+1$. The first element of the \emph{offset} vector must be 0 and the last element must be the number of columns. Remaining elements must follow in a non-decreasing order. The output $i$ of the splitting operation then contains the columns $c$ with $\textit{offset}[i] \le c < \textit{offset}[i+1]$. The following demonstrates the syntax:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x',5,2)
w = horzsplit(x,[0,1,2])
print w[0], w[1]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x',5,2);
w = horzsplit(x,[0,1,2]);
disp w{1}, w{2}
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x',5,2)
w = horzsplit(x,[0,1,2])
print w[0], w[1]
\end{pytexoutput}

The vertsplit operation works analogously, but with the \emph{offset} vector referring to rows:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
w = vertsplit(x,[0,3,5])
print w[0], w[1]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
w = vertsplit(x,[0,3,5]);
disp w{1}, w{2}
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
w = vertsplit(x,[0,3,5])
print w[0], w[1]
\end{pytexoutput}

Note that it is always possible to use slice element access (cf. Section~\ref{sec:getset}) instead of horizontal and vertical splitting, for the above vertical splitting:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
w = [x[0:3,:], x[3:5,:]]
print w[0], w[1]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
w = {x(1:3,:), x(4:5,:)};
disp w{1}, w{2}
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
w = [x[0:3,:], x[3:5,:]]
print w[0], w[1]
\end{pytexoutput}

For \texttt{SX} graphs, this alternative way is completely equivalent, but for \texttt{MX} graphs using \texttt{horzsplit}/\texttt{vertsplit} is \emph{significantly more efficient when all the splitted expressions are needed}.

\textbf{Inner product}, defined as $<A,B> := \trace{A \, B} = \sum_{i,j} \, A_{i,j} \, B_{i,j}$ are created as follows:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x',2,2)
print inner_prod(x,x)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x',2,2)
disp inner_prod(x,x)
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x',2,2)
print inner_prod(x,x)
\end{pytexoutput}

Many of the above operations are also defined for the \texttt{Sparsity} class (Section~\ref{sec:sparsity_class}), e.g. \texttt{vertcat}, \texttt{horzsplit}, transposing, addition (which returns the \emph{union} of two sparsity patterns) and multiplication (which returns the \emph{intersection} of two sparsity patterns).

\section{Querying properties}
You can check if a matrix or sparsity pattern has a certain property by calling an appropriate member function. e.g.

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
y = SX.sym('y',10,1)
print y.shape
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
y = SX.sym('y',10,1);
print size(y)
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
y = SX.sym('y',10,1)
print y.shape
\end{pytexoutput}

Note that in MATLAB, \lstinline[language=Matlab]{obj.myfcn(arg)} and \lstinline[language=Matlab]{myfcn(obj, arg)} are both valid ways of calling a member function \texttt{myfcn}. The latter variant is probably preferable from a style viewpoint.

Some commonly used properties for a matrix \emph{A} are:
\begin{description}
  \item[\emph{A}.size1()] The number of rows
  \item[\emph{A}.size2()] The number of columns
  \item[\emph{A}.shape] (in MATLAB "size") The shape, i.e. the pair (\emph{nrow},\emph{ncol})
  \item[\emph{A}.numel()] The number of elements, i.e $\textit{nrow} * \textit{ncol}$
  \item[\emph{A}.nnz()] The number of structurally nonzero elements, equal to \emph{A}.numel() if \emph{dense}.
  \item[\emph{A}.sparsity()] Retrieve a reference to the sparsity pattern
  \item[\emph{A}.isdense()] Is a matrix dense, i.e. having no structural zeros
  \item[\emph{A}.isscalar()] Is the matrix a scalar, i.e. having dimensions 1-by-1?
  \item[\emph{A}.iscolumn()] Is the matrix a vector, i.e. having dimensions $n$-by-1?
  \item[\emph{A}.issquare()] Is the matrix square?
  \item[\emph{A}.istriu()] Is the matrix upper triangular?
  \item[\emph{A}.isConstant()] Are the matrix entries all constant?
  \item[\emph{A}.isInteger()] Are the matrix entries all integer-valued?
\end{description}

The last queries are examples of queries for which \emph{false negative} returns are allowed. A matrix for which \emph{A}.isConstant() is \emph{true} is guaranteed to be constant, but is \emph{not} guaranteed to be non-constant if \emph{A}.isConstant() is \emph{false}. We recommend you to check the API documentation for a particular function before using it for the first time.

\section{Linear algebra}
\CasADi supports a limited number of linear algebra operations, e.g. for solution of linear systems of equations:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
A = MX.sym('A',3,3)
b = MX.sym('b',3)
print solve(A,b)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
A = MX.sym('A',3,3);
b = MX.sym('b',3);
disp A\b
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
A = MX.sym('A',3,3)
b = MX.sym('b',3)
print solve(A,b)
\end{pytexoutput}

\section{Calculus}
Basic calculus operations are also possibly and implemented very efficiently using \emph{algorithmic differentiation} (AD) as outlined in Chapter~\ref{ch:function}.

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
A = SX.sym('A',3,3)
x = SX.sym('x',3)
print jacobian(mul(A,x),x)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
A = SX.sym('A',3,3);
x = SX.sym('x',3);
print jacobian(A*x,x)
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
A = SX.sym('A',3,3)
x = SX.sym('x',3)
print jacobian(mul(A,x),x)
\end{pytexoutput}

\chapter{Function objects} \label{ch:function}

\section{\texttt{Function}} \label{sec:function}
\CasADi allows the user to create function objects, in C++ terminology often referred to as \emph{functors}. This includes functions that are defined by a symbolic expression, ODE/DAE integrators, QP solvers, NLP solvers etc.

Function objects are typically created with the syntax:
\begin{lstlisting}[language=Python]
f = functionname(name, arguments, ..., [options])
\end{lstlisting}

The name is mainly a display name that will show up in e.g. error messages or as comments in generated C code. This is followed by a set of arguments, which is class dependent. Finally, the user can pass an options structure for customizing the behavior of the class. The options structure is a dictionary type in Python, a struct in MATLAB or \CasADi's \texttt{Dict} type in C++.

A \texttt{Function} can be constructed by passing a list of input expressions and a list of output expressions:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x',2,2)
y = SX.sym('y')
f = Function('f',[x,y],\
           [x,sin(y)*x])
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x',2,2);
y = SX.sym('y');
f = Function('f',{x,y},...
           {x,sin(y)*x});
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x',2,2)
y = SX.sym('y')
f = Function('f',[x,y],\
           [x,sin(y)*x])
\end{pytexoutput}

which defines a function $f : \mathbb{R}^{2 \times 2} \times \mathbb{R}, \quad (x,y) \mapsto (x,\sin(y) x)$.
Note that all function objects in \CasADi, including the above, are multiple matrix-valued input, multiple, matrix-valued output.

\texttt{MX} expression graphs work the same way:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = MX.sym('x',2,2)
y = MX.sym('y')
f = Function('f',[x,y],\
               [x,sin(y)*x])
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = MX.sym('x',2,2);
y = MX.sym('y');
f = Function('f',{x,y},...
               {x,sin(y)*x});
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = MX.sym('x',2,2)
y = MX.sym('y')
f = Function('f',[x,y],\
               [x,sin(y)*x])
\end{pytexoutput}

All derived classes of \texttt{Function} come with a range of options that can be set. The API documentation shows the list of available options for each class, along with their default values and descriptions.

\section{Input-output schemes for function objects}
Most \texttt{Function}-derived classes have a particular input/output signature with them and/or take as arguments in the constructor other function objects (callback functions) with a particular input/output signature. For example, as we shall see in Chapter~\ref{ch:nlp}, a \emph{nonlinear program} (NLP) is defined by two inputs (the decision variable and a set of parameters) and two outputs (the objective and constraint functions). To make it easier to remember the number and order of the input/output arguments, \CasADi provides helper functions of the form:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x')
p = SX.sym('p')
f = x**2
g = log(x)-p
nlp = Function('nlp',
        [x,p],[f,g],
        ['x','p'],
        ['f','g'])
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x');
p = SX.sym('p');
f = x^2;
g = log(x)-p;
nlp = Function('nlp',...
        {x,p},{f,g},...
        char('x','p'),...
        char('f','g'));
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x')
p = SX.sym('p')
f = x**2
g = log(x)-p
nlp = Function('nlp',
        [x,p],[f,g],
        ['x','p'],
        ['f','g'])
\end{pytexoutput}

The last line is essentially equivalent to \lstinline[language=Python]{Function('nlp',[x,p],[f,g])}, but is preferred for a number of reasons:
\begin{itemize}
\item No need to remember the number or order of arguments
\item Inputs or outputs that are absent can be left unset
\item The helper functions provide meta-information that allows inputs to be referred to by their names instead of their index. E.g. \verb|nlp.jacobian('x','g')| instead of \verb|nlp.jacobian(0,1)|.
\end{itemize}

\section{Calling function objects}
\texttt{MX} expressions may contain calls to \texttt{Function}-derived functions. Calling a function object is both done for the numerical evaluation and, by passing symbolic arguments, for embedding a \emph{call} to the function object into an expression graph (cf. also Chapter~\ref{ch:integrators}).

There are two principle ways of calling a function object, by passing a list (in MATLAB a cell array, in C++ an \lstinline[language=C++]{std::vector<MatrixType>}) of inputs (of the same length as the number of inputs to the function) or by passing a dictionary (\texttt{dict} in Python, \texttt{struct} in MATLAB and \lstinline[language=C++]{std::map<std::string, MatrixType>} in C++).

The output will be of the same type, i.e. a list of outputs and a dictionary of outputs, respectively.

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
res = nlp([1.1,3.3])
print res[0], res[1]
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
res = nlp({1.1,3.3});
disp res{1}, res{2}
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
res = nlp([1.1,3.3])
print res[0], res[1]
\end{pytexoutput}

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
res = nlp({'x':1.1,\
           'p':3.3})
print res['f'], res['g']
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
res = nlp(struct('x',1.1,...
                 'p',3.3));
disp res.f, res.g
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
res = nlp({'x':1.1,\
           'p':3.3})
print res['f'], res['g']
\end{pytexoutput}

The recommendation is to always work with named inputs and outputs, since it is less error prone and more maintainable. When creating a function from expressions, not from the scheme helpers as above, you can specify the input and output schemes by passing the "input\_scheme" and "output\_scheme" option to the \texttt{Function}constructor:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x')
p = SX.sym('p')
f = x**2
g = log(x)-p
op = \
 {'input_scheme':['x','p'],\
  'output_scheme':['f','g']}
nlp = Function('nlp',\
          [x,p],[f,g],op)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x');
p = SX.sym('p');
f = x^2;
g = log(x)-p;
op = struct;
op.input_scheme=char('x','p');
op.output_scheme=char('f','g');
nlp = Function('nlp',...
          {x,p},{f,g},op);
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x')
p = SX.sym('p')
f = x**2
g = log(x)-p
op = \
 {'input_scheme':['x','p'],\
  'output_scheme':['f','g']}
nlp = Function('nlp',\
          [x,p],[f,g],op)
\end{pytexoutput}

Note that the dimensions (but not necessarily the sparsity pattern) of the evaluation arguments have to match those of the function inputs, with two exceptions:
\begin{itemize}
  \item A row vector can be passed instead of a column vector and vice versa.
  \item A scalar argument can always be passed, regardless of the input dimension. This has the meaning of setting all elements of the input matrix to that value.
\end{itemize}

Note that the function call syntax always expects a vector of inputs, so if your function only has a single input, you need to turn it into a single element list (in Python) or cell array (in MATLAB). Similarly, the function always returns a list of outputs (in MATLAB, a cell array, in C++ an \lstinline[language=C++]{std::vector}).

\section{Algorithmic differentiation}

The single most central functionality of \CasADi is \emph{algorithmic (or automatic) differentiation} (AD).

Assume a function $\mathbf{R}^N \rightarrow \mathbf{R}^M$:
\begin{equation}
 y = f(x)
\end{equation}

\emph{Forward mode} directional derivatives can be used to calculate Jacobian-times-vector products:
\begin{equation}
 y_{\text{fsens}} = \frac{\partial f}{\partial x} \, x_{\text{fseed}}
\end{equation}
We will refer to the multiplying vector as the \emph{seed} vector and the result as the \emph{sensitivity} vector.

Similarly, \emph{reverse mode} (or \emph{adjoint mode}) directional derivatives can be used to calculate Jacobian-transposed-times-vector products:
\begin{equation}
 x_{\text{asens}} = \left(\frac{\partial f}{\partial x}\right)^{\text{T}} \, y_{\text{aseed}}
\end{equation}

Both forward and adjoint directional derivatives are calculated at a cost proportional to evaluating $f(x)$, \emph{regardless of the dimension of $x$}.

CasADi is also able to generate complete, \emph{sparse} Jacobians efficiently. Internally, the algorithm it will use for this depends on the particular \texttt{Function} class but in most cases consists of the following steps:
\begin{itemize}
 \item Automatically detect the sparsity pattern of the Jacobian
 \item Use graph coloring techniques to find a few forward and/or directional derivatives needed to construct the complete Jacobian
 \item Calculate the directional derivatives numerically or symbolically
 \item Assemble the complete Jacobian
\end{itemize}

Hessians are calculated by first calculating the gradient and then performing the same steps as above to calculate the Jacobian of the gradient in the same way as above, while exploiting symmetry.

\section{Generating Jacobian and Hessian function objects}
You can generate a new function for calculating the Jacobian by calling the \texttt{Function::jacobian} member function:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
J = f.jacobian(id_in,id_out)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
J = f.jacobian(id_in,id_out);
\end{lstlisting}
\end{minipage}

where \texttt{id\_in} and \texttt{id\_out} are either the indices of the inputs and outputs (0-based indexing, also in MATLAB) or strings corresponding to identifier names. In either case, a new function object will be generated that calculates the Jacobian of the \texttt{id\_out}-th function output with respect to the \texttt{id\_in}-th function input. The new function object will have the same input scheme as the function \texttt{f} but with the (sparse) Jacobian as well as all the original function outputs as outputs.

Similarly, the gradient of a scalar output can be called by calling the \texttt{Function::gradient} member function:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
G = f.gradient(id_in,id_out)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
G = f.gradient(id_in,id_out);
\end{lstlisting}
\end{minipage}

which will generate a function with the same input scheme as the function \texttt{f} but with the (sparse) gradient and all the original function outputs as outputs.

Lastly, Hessians of a scalar output can be called by calling the \texttt{Function::hessian} member function:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
G = f.hessian(id_in,id_out)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
G = f.hessian(id_in,id_out);
\end{lstlisting}
\end{minipage}

which will generate a function with the same input scheme as the function \texttt{f} but with the (sparse) Hessian, the gradient and all the original function outputs as outputs.

\section{Converting \texttt{MX} to \texttt{SX}}
An \texttt{MX} graph which only contains built-in operations (e.g. elementwise operations such as addition, square root, matrix multiplications and calls to \texttt{SX} functions, can be converted into a \texttt{SX} graph the syntax:

\begin{lstlisting}[language=Python]
sx_function = mx_function.expand()
\end{lstlisting}

This might speed up the calculations significantly, but might also cause extra memory overhead.

\chapter{ODE/DAE integration and sensitivity analysis} \label{ch:integrators}
\section{ODE/DAE formulation}
The integrators interfaced with \CasADi assumes a DAE residual function of semi-explicit form with quadratures:
\begin{subequations}
\begin{align}
 \dot{x} &= f_{\text{ode}}(t,x,z,p), \qquad x(0) = x_0 \\
      0  &= f_{\text{alg}}(t,x,z,p) \\
 \dot{q} &= f_{\text{quad}}(t,x,z,p), \qquad q(0) = 0
\end{align}
\end{subequations}

For solvers of \emph{ordinary} differential equations, the second equation and the algebraic variables $z$ must be absent.

DAEs of form can be represented as dictionaries:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
x = SX.sym('x')
z = SX.sym('z')
f = -z*x
g = z**2-2
dae = {'x':x, 'z':z,\
  'ode':f, 'alg':g}
print dae
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
x = SX.sym('x');
z = SX.sym('z');
f = -z*x;
g = z^2-2;
dae = struct('x',x,'z',z,...
          'ode',f,'alg',g);
disp(dae)
\end{lstlisting}
\end{minipage}
\begin{pytexoutput}
x = SX.sym('x')
z = SX.sym('z')
f = -z*x
g = z**2-2
dae = {'x':x, 'z':z,\
  'ode':f, 'alg':g}
print dae
\end{pytexoutput}

An integrator in \CasADi is a function that take the state at the initial time, a set of parameters, the state vector at the initial time and a guess for the algebraic variables (only for DAEs) and returns the state vector and algebraic variables at the final time.

\begin{lstlisting}[language=Python]
integrator = Function.integrator(display_name,plugin_name,dae,options)
\end{lstlisting}

The time horizon is assumed to be fixed\footnote{for problems with free end time, you can always scale time by introducing an extra parameter and substitute $t$ for a dimensionless time variable that goes from 0 to 1} and can be changed from its default [0, 1] by setting the options "t0" and "tf".

\section{Sundials integrators}
The freely available \htmladdnormallink{SUNDIALS suite}{https://computation.llnl.gov/casc/sundials/description/description.html} (distributed along with \CasADi) contains the two popular integrators CVodes and IDAS for ODEs and DAEs respectively. These integrators have support for forward and adjoint sensitivity analysis and when used via \CasADi's Sundials interface, \CasADi will automatically formulate the Jacobian information, which is needed by the backward differentiation formula (BDF) that CVodes and IDAS use. Also automatically formulated will be the forward and adjoint sensitivity equations. This means that the only information that the user needs to provide is the DAE residual function:

\begin{lstlisting}[language=Python]
integrator = Function.integrator('my_idas','idas',dae)
\end{lstlisting}
\begin{pytexoutput}
integrator = Function.integrator('my_idas','idas',dae)
\end{pytexoutput}

And equivivalently for CVodes (the "cvodes" integrator plugin in \CasADi).

For a list of options for the integrators, as well as the input and output schemes of this \emph{function}, check the documentation directly from Python:

\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Python]
print Integrator.doc('cvodes')
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\begin{lstlisting}[language=Matlab]
disp(Integrator.doc('cvodes'))
\end{lstlisting}
\end{minipage}

or by consulting the online C++ API docs on the website.

\section{Sensitivity analysis}
From evaluation point of view, an integrator behaves just like the \texttt{Function} introduced in the previous section. Use the member functions of in the Function class to generate new function objects corresponding to directional derivatives (forward or reverse mode) or complete Jacobians. Then evaluate these function objects numerically to obtain sensitivity information. The documented example "sensitivity\_analysis" (available in \CasADi's example collection for Python, MATLAB and C++) demonstrate how \CasADi can be used to calculate first and second order derivative information (forward-over-forward, forward-over-adjoint, adjoint-over-adjoint) for a simple DAE.

\section{The \texttt{Simulator} class}
As already mentioned, integrators in \CasADi are functions that calculates the state at the final time. Often, however, a user is interested in obtaining the solution at multiple time points. This can often be done more efficiently than by repeatedly calling \texttt{integrator.evaluate()}. The easiest way to use this functionality is to use the \texttt{Simulator} class.

A \texttt{Simulator} can be created using the syntax:

\begin{lstlisting}[language=Python]
  # Allocate an integrator instance
  integrator = ...

  # Choose a time grid
  tgrid = [0, 10, 20, 30, 40]

  # Create a simulator
  simulator = Simulator('my_simulator',integrator, time_grid)
\end{lstlisting}

and equivalently in MATLAB and C++.

A \texttt{Simulator} can be used just like an integrator, and its input scheme is the same. Its output is now matrix valued, with the the columns corresponding to different time points. The class can also be used to evaluate a particular function of the state at a set of time points. See the API documentation and the documented examples for more information.

\chapter{Nonlinear programming} \label{ch:nlp}
The NLP solvers contained in or interfaced with \CasADi solves parametric NLPs of the following form:
\begin{equation}
\begin{array}{cc}
\begin{array}{c}
\text{minimize:} \\
x \in \mathbb{R}^{nx}, p \in \mathbb{R}^{np}
\end{array}
&
f(x,p)
\\
\begin{array}{c}
\text{subject to:}
\end{array}
&
\begin{array}{c}
x_{\min} \le x \le x_{\max} \\
g_{\min} \le g(x,p) \le g_{\max}
\end{array}
\end{array}
\end{equation}

With a function \texttt{nlp}, which given $x$ and $p$, gives $f$ and $g$, an NLP solver instance can be allocated by:
\begin{lstlisting}[language=Python]
nlp_solver = Function.nlp_solver(display_name,plugin_name,nlp,options)
\end{lstlisting}

The interface will then automatically generate the information that it might need to solve the NLP, which may be solver and option dependent. Typically an NLP solver will need a function that gives the Jacobian of the constraint function and a Hessian of the Lagrangian function ($L(x,\lambda) = f(x) + \lambda^{\text{T}} \, g(x))$ with respect to $x$. The interface will generate this kind of information automatically and provide to the solver.

NLP solvers, like ODE/DAE integrators are functions in \CasADi (though taking derivatives of them is currently not supported). You will find the input and output schemes in the \CasADi API documentation on the website or by using the question mark in Python.

\chapter{Optimal control with \CasADi}
\CasADi can be used to solve \emph{optimal control problems} (OCP) using a variety of methods, including direct (a.k.a. \emph{discretize-then-optimize}) and indirect (a.k.a. \emph{optimize-then-discretize}) methods, all-at-once (e.g. collocation) methods and shooting-methods requiring embedded solvers of initial value problems in ODE or DAE. As a user, you are in general expected to \emph{write your own OCP solver} and \CasADi aims as making this as easy as possible by providing powerful high-level building blocks. Since you are writing the solver yourself (rather than calling an existing ``black-box'' solver), a basic understanding of how to solve OCPs is indispensable. Good, self-contained introductions to numerical optimal control can be found in the recent textbooks by Biegler\footnote{Lorenz T. Biegler, \emph{\htmladdnormallink{Nonlinear Programming: Concepts, Algorithms, and Applications to Chemical Processes}{http://books.google.es/books/about/Nonlinear_Programming.html?id=VdB1wJQu0sgC&redir_esc=y}}, SIAM 2010} or Betts\footnote{John T. Betts, \emph{\htmladdnormallink{Practical Methods for Optimal Control Using Nonlinear Programming}{http://books.google.es/books/about/Practical_Methods_for_Optimal_Control_Us.html?id=Yn53JcYAeaoC&redir_esc=y}}, SIAM 2001} or Moritz Diehl's lecture notes on \htmladdnormallink{numerical optimal control}{http://homes.esat.kuleuven.be/~mdiehl/NUMOPT/numopt.pdf}.

\section{Optimization of a Van der Pol oscillator}
In \CasADi's examples collection\footnote{You can obtain this collection as an archive named \texttt{examples\_pack.zip} in \CasADi's \htmladdnormallink{download area}{http://files.casadi.org}}, you find codes for solving simple optimal control problem using a variety of different methods. The problem is driving a \emph{Van der Pol} oscillator to the origin, while trying to minimize a quadratic cost:
\begin{equation}
\begin{array}{lc}
\begin{array}{l}
\text{minimize:} \\
x(\cdot) \in \mathbb{R}^2, \, u(\cdot) \in \mathbb{R}
\end{array}
\quad \displaystyle \int_{t=0}^{10}{(x_0^2 + x_1^2 + u^2) \, dt}
\\
\\
\text{subject to:} \\
\\
\begin{array}{ll}
\left\{
\begin{array}{l}
\dot{x}_0 = (1-x_1^2) \, x_0 - x_1 + u \\
\dot{x}_1 = x_0 \\
-0.75 \le u \le 1.0
\end{array} \right. & \text{for $0 \le t \le 10$} \\
x_0(0)=0, \quad x_0(10)=0  \\
x_1(0)=1, \quad x_1(10)=0
\end{array}
\end{array}
\label{eq:vdp}
\end{equation}

\section{Direct single-shooting}
The simplest OCP method to implement in \CasADi is single-shooting. In fact, it can be implemented in just 30 lines of code, which the script {\texttt{vdp\_single\_shooting.py}} in \CasADi's examples collection demonstrates. Please go through the code carefully and make sure that you understand the principle. The most important part of the code are the lines:
\begin{verbatim}
# Build a graph of integrator calls
for k in range(nk):
  X,QF = itemgetter('xf','qf')(integrator({'x0':X,'p':U[k]}))
  f += QF
\end{verbatim}

Here, we recursively construct a symbolic expression for the state at the final time. This expression is then used in the formulation of the NLP objective and constraint functions.

\section{Direct multiple-shooting}
The second optimal control method we shall consider is multiple shooting. In multiple shooting, the states at each ''shooting node'' are degrees of freedom in the NLP. The script \\ \texttt{vdp\_multiple\_shooting.py} demonstrates how the VDP problem can be solved using direct multiple shooting in \CasADi.

Note how the symbolic variable in the NLP functions now contains both the control and states for each of the \texttt{nk} intervals:
\begin{verbatim}
# Total number of variables
nv = 1*nk + 3*(nk+1)

# Declare variable vector
V = MX.sym("V", nv)
\end{verbatim}

Also note how the recursive overwriting of \texttt{X} has been replaced with:
\begin{verbatim}
for k in range(nk):
  # Local state vector
  Xk = vertcat((X0[k],X1[k],X2[k]))
  Xk_next = vertcat((X0[k+1],X1[k+1],X2[k+1]))

  # Call the integrator
  Xk_end = integrator({'x0':Xk,'p':U[k]})["xf"]

  # append continuity constraints
  g.append(Xk_next - Xk_end)
  g_min.append(NP.zeros(Xk.nnz()))
  g_max.append(NP.zeros(Xk.nnz()))
\end{verbatim}

\section{Direct collocation}
When we went from direct single shooting to direct multiple shooting we essentially traded nonlinearity for problem size. The NLP in single shooting is small, but often highly nonlinear, whereas the NLP for multiple-shooting is larger, but less nonlinear and with a sparsity structure that can be exploited efficiently. Direct collocation is to take one more step in the same direction, adding even more degrees of freedom. The resulting NLP is even larger, but has even more structure that can be exploited.

While multiple shooting only includes the state at the beginning of each control interval as a degree of freedom in the NLP (in addition to the discretized control and the parameters), in direct collocation the state at a set of \emph{collocation points} (in addition to the beginning of the interval) enters in the NLP as variables. An example of a choice of time points are the \emph{Legendre points} of order $d=3$ :
\begin{equation}
 \tau = [0,0.112702,0.500000,0.887298]
\end{equation}

Keeping the same control discretization as in single and multiple shooting:
\begin{equation}
 u(t) = u_k, \quad \text{for $t \in [t_k, t_{k+1}], \quad k=0,\ldots,n_k-1$}
\end{equation}

the complete list of time points, with $h_k := t_{k+1}-t_k$, is:
\begin{equation}
 t_{k,j} := t_k + h_k \, \tau_j, \quad \text{for $k=0,\ldots,n_k-1$ and $j=0,\ldots,d$}
\end{equation}
as well as the final time $t_{n_k,0}$. Also let $x_{k,j}$ denote the states at these time points.

On each control interval, we shall define a Lagrangian polynomial basis:
\begin{equation}
 L_j(\tau) = \prod_{r=0, \, r \ne j}^{d} \frac{\tau - \tau_{r}}{\tau_j - \tau_r}
\end{equation}

Since the Lagrangian basis satisfies:
\begin{equation}
 L_j(\tau_r) = \left\{
 \begin{array}{l}
  1, \qquad \text{if $j=r$} \\
  0, \qquad \text{otherwise}
 \end{array}
  \right.
\end{equation}
we can approximate the state trajectory approximation as a linear combination of these basis functions:
\begin{equation}
\tilde{x}_k(t) = \sum_{r=0}^{d}{L_r\left(\frac{t-t_k}{h_k}\right) \, x_{k,r}}
\end{equation}

In particular we get approximations of the state time derivative at each collocation point (not including $\tau_0$):
\begin{equation}
\tilde{\dot{x}}_k(t_{k,j}) = \frac{1}{h_k} \, \sum_{r=0}^{d}{\dot{L}_r(\tau_j) \, x_{k,r}} := \frac{1}{h_k} \, \sum_{r=0}^{d}{C_{r,j} \, x_{k,r}}
\label{eq:colldef}
\end{equation}

as well as an approximation of the state at the end of the control interval:
\begin{equation}
\tilde{x}_{k+1,0} = \sum_{r=0}^{d}{L_r(1) \, x_{k,r}} := \sum_{r=0}^{d}{D_r \, x_{k,r}}
\label{eq:contdef}
\end{equation}

Plugging in the approximation of the state derivative (\ref{eq:colldef}) into the ODE gives us a set of \emph{collocation equations} that needs to be satisfied for every state at every collocation point:
\begin{equation}
h_k \, f(t_{k,j},x_{k,j},u_k) - \sum_{r=0}^{d}{C_{r,j} \, x_{k,r}} = 0, \qquad k=0,\ldots,n_k-1, \quad j=1,\ldots,d
\end{equation}

And the approximation of the end state (\ref{eq:contdef}) gives us a set of \emph{continuity equations} that must be satisfied for every control interval:
\begin{equation}
x_{k+1,0} - \sum_{r=0}^{d}{D_r \, x_{k,r}} = 0, \qquad k=0,\ldots,n_k-1,
\end{equation}

These two sets of equations take the place of the continuity equation (represented by the integrator call) in direct multiple shooting. The above equations have been implemented in the script \texttt{vdp\_collocation.py}.

\chapter{Import and reformulation of OCPs from Modelica} \label{ch:modelica}
\CasADi supports importing OCPs formulated in the Modelica modeling language as well as in the Optimica extension of Modelica to optimal control. The import facility currently works with the open-source \htmladdnormallink{JModelica.org}{http://www.jmodelica.org/} compiler.

For instructions on how to install and use JModelica.org, we refer to their \htmladdnormallink{website}{http://www.jmodelica.org/}. Note that a \CasADi build (which may not be the latest) is contained in the pre-built JModelica.org binaries.

\emph{NOTE: The functionality to import and reformulation of OCPs from Modelica is still under development and to be considered unstable.}

\section{Compiling the Modelica code} \label{sec:modelica_compilation}
To see how to use the Modelica import, look at \htmladdnormallink{thermodynamics\_example.py}{https://github.com/casadi/casadi/blob/tested/examples/python/modelica/fritzson_application_examples/thermodynamics_example.py} and \htmladdnormallink{cstr.cpp}{https://github.com/casadi/casadi/blob/tested/examples/cplusplus/cstr.cpp} in \CasADi's example collection.

Assuming that the Modelica/Optimica model \texttt{ModelicaClass.ModelicaModel} is defined in the files \texttt{file1.mo} and \texttt{file2.mop}, the compile command is:
\begin{verbatim}
  from pymodelica import compile_jmu
  jmu_name=compile_jmu('ModelicaClass.ModelicaModel', \
    ['file1.mo','file2.mop'],'auto','ipopt',\
    {'generate_xml_equations':True, 'generate_fmi_me_xml':False})
\end{verbatim}

This will generate a \texttt{jmu}-file, which is essentially a zip file containing, among other things, the file \texttt{modelDescription.xml}. This XML-file contains a symbolic representation of the optimal control problem and can be inspected in a standard XML editor.
\begin{verbatim}
  from zipfile import ZipFile
  sfile = ZipFile(jmu_name','r')
  mfile = sfile.extract('modelDescription.xml','.')
\end{verbatim}

\section{The DaeBuilder class} \label{sec:modelica_import}
\emph{NOTE: The DaeBuilder class (previously called SymbolicOCP) is not yet stable and undergoing refactoring. Fore more information, see \htmladdnormallink{CasADi issue \#1358}{https://github.com/casadi/casadi/issues/1358}.}

The symbolic optimal control problem representation (or just model description) contained in \texttt{modelDescription.xml} can be imported into \CasADi in the form of the DaeBuilder class:
\begin{verbatim}
ocp = DaeBuilder()
\end{verbatim}

The \texttt{DaeBuilder} class contains symbolic representation of the optimal control problem designed to be general and allow manipulation. The basic usage of this class is to call the member function \texttt{parseFMI} with the XML file name:
\begin{verbatim}
ocp.parseFMI('modelDescription.xml')
\end{verbatim}

Symbolic expressions corresponding to the states, controls parameters etc. are directly accessible as member variables of the \texttt{DaeBuilder} object. E.g. the free controls can be accessed as \verb|ocp.u|. Symbolic expressions for the OCP are either accessible in the same way (e.g. \verb|ocp.dae| will return the equations for the fully-implicit differential-algebraic equation formulation used by Modelica. Other equations are tied to a particular variable. E.g. the \emph{binding equations} corresponding to the set of \emph{independent parameters} can be retrieved as \verb|ocp.beq(ocp.pi)|.

Other useful commands available for an instance \texttt{ocp} of \texttt{DaeBuilder} include:
\begin{description}
\item[print \texttt{ocp}] Print the optimal optimal control problem to screen
\item[\texttt{ocp}.makeExplicit()] Reformulate the OCP in fully-explicit form
\item[\texttt{ocp}.scaleVariable()] Scale all variables using the \emph{nominal} attribute for each variable
\item[\texttt{ocp}.eliminateIndependentParameters()] Eliminate all independent parameters from the symbolic expressions
\end{description}

For a more detailed description of this class and its functionalities, we refer to the API documentation. We also recommend potential users to have a look at the {\texttt{modelica\_ms.py}} tutorial example.

\chapter{Difference in usage from different languages} \label{ch:syntax_differences}

\section{General usage}
\begin{center}
  \scriptsize
  \begin{tabular}{| p{3.5cm} | p{3.5cm} | p{3.5cm} | p{3.5cm} | }
    \hline
      & Python & C++ & MATLAB \\ \hline
    Starting \CasADi & \verb|from casadi import *| & \verb|#include \| \verb|"casadi/casadi.hpp"| \verb|using namespace casadi;| & \verb|import casadi.*| \\ \hline
    Printing the \emph{representation} (string representation intended to be \emph{unambiguous}) & \verb|A <ENTER>| (interactive), \verb|print repr(A)| (in scripts) & \verb|std::cout << A;|& \verb|A <ENTER>| or \verb|disp A|\\ \hline
    Printing the \emph{description} (string representation intended to be \emph{readable}) & \verb|print A| & \verb|A.print();| or \verb|A.print(stream);|& \verb|A.print()| \\ \hline
    Calling a class function & \verb|SX.zeros(3,4)| & \verb|SX::zeros(3,4)| & \verb|SX.zeros(3,4)|\\ \hline
    Creating a dictionary (e.g. for options) & \verb|d = {'opt1':opt1}| or \verb|d = {}; a['opt1'] = opt1| & \verb|a = Dict();| \verb|a['opt1'] = opt1;| & \verb|a = struct;| \verb|a.opt1 = opt1;| \\ \hline
  \end{tabular}
\end{center}

\section{List of operations}
The following is a list of the most important operations. Operations that differ between the different
languages are marked with a star (*). This list is neither complete, nor does it show all the variants of
each operation. Further information is available in the API documentation.

\begin{center}
  \scriptsize
  \begin{tabular}{| p{3.5cm} | p{3.5cm} | p{3.5cm} | p{3.5cm} | }
    \hline
      & Python & C++ & MATLAB \\ \hline
    Addition, subtraction
    & \verb|x+y, x-y, -x| & \verb|x+y, x-y, -x| & \verb|x+y, x-y, -x| \\ \hline
    *Elementwise multiplication, division
    & \verb|x*y, x/y| & \verb|x*y, x/y| & \verb|x.*y, x./y| \\ \hline
    Natural exponential function and logarithm
    & \verb|exp(x)| \linebreak \verb|log(x)|
    & \verb|exp(x)| \linebreak \verb|log(x)|
    & \verb|exp(x)| \linebreak \verb|log(x)| \\ \hline
    *Exponentiation & \verb|x**y|
    & \verb|pow(x,y)| & \verb|x^y| or \verb|x.^y| \\ \hline
    Square root & \verb|sqrt(x)|
    & \verb|sqrt(x)| & \verb|sqrt(x)| \\ \hline
    Trigonometric functions & \verb|sin(x), cos(x), tan(x)| & \verb|sin(x), cos(x), tan(x)| & \verb|sin(x), cos(x), tan(x)| \\ \hline
    *Inverse trigonometric & \verb|asin(x), acos(x), ...| & \verb|arcsin(x), arccos(x), ...| & \verb|asin(x), acos(x), ...| \\ \hline
    Two argument arctangent & \verb|atan2(x, y)| & \verb|arctan2(x, y)| & \verb|atan2(x, y)| \\ \hline
    Hyperbolic functions & \verb|sinh(x), cosh(x), tanh(x)| & \verb|sinh(x), cosh(x), tanh(x)| & \verb|sinh(x), cosh(x), tanh(x)| \\ \hline
    *Inverse hyperbolic & \verb|asinh(x), acosh(x), ...| & \verb|arcsinh(x), arccosh(x), ...| & \verb|asinh(x), acosh(x), ...| \\ \hline
    Inequalities & \verb|a<b, a<=b, a>b, a>=b| & \verb|a<b, a<=b, a>b, a>=b| & \verb|a<b, a<=b, a>b, a>=b| \\ \hline
    *(Not) equal to & \verb|a==b, a!=b| & \verb|a==b, a!=b| & \verb|a==b, a~=b| \\ \hline
    *Logical and & \verb|logic_and(a, b)| &\verb|a && b| &  \verb|a & b| \\ \hline
    *Logical or  & \verb|logic_or(a, b)| & \verb=a || b= & \verb=a | b= \\ \hline
    *Logical not & \verb|logic_not(a)| & \verb|!a| & \verb|~a| \\ \hline
    Round to integer
    & \verb|floor(x), ceil(x)| & \verb|floor(x), ceil(x)| & \verb|floor(x), ceil(x)| \\ \hline
    *Modulus after division
    & \verb|fmod(x, y)| & \verb|fmod(x, y)| & \verb|mod(x, y)| \\ \hline
    *Absolute value
    & \verb|fabs(x)| & \verb|fabs(x)| & \verb|abs(x)| \\ \hline
    Sign function
    & \verb|sign(x)| & \verb|sign(x)| & \verb|sign(x)| \\ \hline
    (Inverse) error function
    & \verb|erf(x), erfinv(x)| & \verb|erf(x), erfinv(x)| & \verb|erf(x), erfinv(x)| \\ \hline
    *Elementwise min and max
    & \verb|fmin(x, y), fmax(x, y)| & \verb|fmin(x, y), fmax(x, y)| & \verb|min(x, y), max(x, y)| \\ \hline
    Index of first nonzero
    & \verb|find(x)| & \verb|find(x)| & \verb|find(x)| \\ \hline
    If-then-else
    & \verb|if_else(c, x, y)| & \verb|if_else(c, x, y)| & \verb|if_else(c, x, y)| \\ \hline
    *Matrix multiplication
    & \verb|mul(x,y)| & \verb|mul(x,y)| & \verb|mul(x,y)| or \verb|x*y| \\ \hline
    *Transpose
    & \verb|transpose(A)| or \verb|A.T| & \verb|transpose(A)| or \verb|A.T()|& \verb|transpose(A)| or \verb|A'| or \verb|A.'| \\ \hline
    Inner product
    & \verb|inner_prod(x, y)| & \verb|inner_prod(x, y)| & \verb|inner_prod(x, y)| \\ \hline
    *Horizontal/vertical concatenation
    & \verb|horzcat([x, y])| \linebreak \verb|vertcat([x, y])|
    & \verb|horzcat(v)| \verb|vertcat(v)|, \linebreak (\verb|v| vector of matrices)
    & \verb|[x, y]| \linebreak \verb|[x; y]| \\ \hline
    Horizontal/vertical split (inverse of concatenation)
    & \verb|vertsplit(x)|, \verb|horzsplit(x)| & \verb|vertsplit(x)|, \verb|horzsplit(x)| & \verb|vertsplit(x)|, \verb|horzsplit(x)| \\ \hline
    *Element access
    & \verb|A[i,j]| and \verb|A[i]|, \linebreak \emph{0-based}
    & \verb|A(i,j)| and \verb|A(i)|, \linebreak \emph{0-based}
    & \verb|A(i,j)| and \verb|A(i)|, \linebreak \emph{1-based} \\ \hline
    *Element assignment
    & \verb|A[i,j] = b| and \verb|A[i] = b|, \linebreak \emph{0-based}
    & \verb|A(i,j) = b| and \verb|A(i) = b|, \linebreak \emph{0-based}
    & \verb|A(i,j) = b| and \verb|A(i) = b|, \linebreak \emph{1-based} \\ \hline
    *Nonzero access
    & \verb|A.nz[k]|, \emph{0-based}
    & \verb|A[k]|, \emph{0-based}
    & (currently unsupported) \\ \hline
    *Nonzero assignment
    & \verb|A.nz[k] = b|, \emph{0-based}
    & \verb|A[k] = b|, \emph{0-based}
    & (currently unsupported) \\ \hline
    Project to a different sparsity
    & \verb|project(x, s)| & \verb|project(x, s)| & \verb|project(x, s)| \\ \hline
  \end{tabular}
\end{center}

%\bibliographystyle{plain}
%\bibliography{ug_cites}
\end{document}
